{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp heatmaps_novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95559d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac9241",
   "metadata": {},
   "source": [
    "# Heatmaps \n",
    "> This module is to create heatmaps for given books. It even includes some functions to generate smaller heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from clean_plot.utils import *\n",
    "from clean_plot.utils import check_files\n",
    "from clean_plot.pickle import label\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastcore.all import *\n",
    "from fastcore.xtras import *\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540a16a",
   "metadata": {},
   "source": [
    "## Methods of `pkl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc8662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deven\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| local\n",
    "%cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def heatmap_from_pkl(\n",
    "    path:str='.', # path to pkl files \n",
    "    min_labels:bool=False, # flag to use shorter labels\n",
    "    std:bool=False, # flag to standardize\n",
    "    corr:bool=False, # flag to save corr plot\n",
    "    )->None:\n",
    "    \"Plot timeseries from the pkl file\"\n",
    "    p = Path(path).absolute()\n",
    "    files = globtastic(p, recursive=False, file_glob='*.pkl').map(Path)\n",
    "    print(f'Current path {p}')\n",
    "    \n",
    "    if not check_files(files):\n",
    "        return\n",
    "        \n",
    "    for f in files:\n",
    "        title = f.stem.split('_whole')[0].replace('_', ' ').title()\n",
    "        print(title)\n",
    "        data = load_pickle(f)\n",
    "        for i in range(len(data)):\n",
    "            try:\n",
    "                df = pd.DataFrame(data[i])\n",
    "            except:\n",
    "                print('Corrupt data in the pkl file')\n",
    "            \n",
    "            vals = df.values\n",
    "            if std:\n",
    "                norm = zscore(normalize(vals))\n",
    "            else:\n",
    "                norm = normalize(vals)\n",
    "                \n",
    "            \n",
    "            \n",
    "            organized_labels = ['DeCLUTR Base', 'InferSent FastText','DistilBERT',\n",
    "                                'RoBERTa', 'USE', 'MPNet', 'XLM', 'MiniLM']\n",
    "            sm_labels = ['DC', 'I-F', 'DB', 'RB', 'USE', 'MPNet', 'XLM', 'MiniLM']\n",
    "            \n",
    "            df2 = df[organized_labels]\n",
    "            \n",
    "            if min_labels:\n",
    "                df2.columns = sm_labels\n",
    "            \n",
    "            if corr:\n",
    "                corr_path = p.parent/'corr'\n",
    "                corr_path.mkdir(exist_ok=True)\n",
    "                \n",
    "                \n",
    "                sns.heatmap(df2.corr(), cmap = 'hot', vmin = 0, vmax = 1,\n",
    "                        xticklabels = False, square = True, annot=True, fmt='.2f')\n",
    "                plt.savefig(corr_path/f'{title}_corr.png', dpi = 300, bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                \n",
    "            if std:\n",
    "                vmin = np.min(df2.values) - 1\n",
    "                vmax = np.max(df2.values) + 1\n",
    "                ts = p.parent/'ts_std'\n",
    "                ts.mkdir(exist_ok=True)\n",
    "            else:\n",
    "                vmin = 0\n",
    "                vmax = 1\n",
    "                ts = p.parent/'ts'\n",
    "                ts.mkdir(exist_ok=True)\n",
    "\n",
    "            ax = sns.heatmap(df2.T, cmap = 'hot', vmin=vmin, vmax=vmax, \n",
    "                             xticklabels = 100, yticklabels=df2.columns)\n",
    "            for j in range(len(df2.columns)):\n",
    "                ax.axhline(j, color='white', lw=1)\n",
    "            ticks = np.linspace(0, len(df), 5, dtype=int)\n",
    "            labels = np.linspace(1, len(df), 5, dtype=int)\n",
    "            plt.xticks(ticks, labels, rotation=0)\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.savefig(ts/f'{title}_ts.png', dpi = 300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "        print('-'*45)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b28f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path /home/deven/embeddings/A_Modest_Proposal/pkl\n",
      "Found 1 pkl files\n",
      "---------------------------------------------\n",
      "A Modest Proposal\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| local\n",
    "heatmap_from_pkl(path = 'embeddings/A_Modest_Proposal/pkl', \n",
    "                min_labels=True,\n",
    "                std = True,\n",
    "                corr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22ee9a",
   "metadata": {},
   "source": [
    "## Methods of SSMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea177d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def plot_novels(path: str=None, # path for embeddings\n",
    "                start: int=0, # start for section\n",
    "                end: int= -1, # end for section\n",
    "                x: bool=False, # x-ticks\n",
    "                y: int=5, # y-ticks,\n",
    "                std: bool=False, # flag to standardize\n",
    "               ):\n",
    "    \"Generates plots for embeddings in the folder\"\n",
    "    \n",
    "#     d = {}\n",
    "    \n",
    "    if start == 0 and end == -1:\n",
    "        pass\n",
    "    elif start>= 0 and end == -1:\n",
    "        pass\n",
    "    else:\n",
    "        assert start < end, 'Incorrect bounds'\n",
    "    \n",
    "    # Marker for xticks and yticks\n",
    "    if x == -1:\n",
    "        x = False\n",
    "    if y == -1:\n",
    "        y = False\n",
    "    \n",
    "    files = globtastic(path, recursive=False, file_glob='*.npy').map(Path)\n",
    "    if not check_files(files):\n",
    "        return\n",
    "    \n",
    "    curr = Path.cwd()\n",
    "    if std:\n",
    "        if start > 0:\n",
    "            new_path = curr/f'sections_{start} {end}_std'\n",
    "            new_path.mkdir(exist_ok=True)\n",
    "        else:\n",
    "            new_path = curr/'full_plots_std'\n",
    "            new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        if start > 0:\n",
    "            new_path = curr/f'sections_{start} {end}'\n",
    "            new_path.mkdir(exist_ok=True)\n",
    "        else:\n",
    "            new_path = curr/'full_plots'\n",
    "            new_path.mkdir(exist_ok=True)\n",
    "            \n",
    "    for f in files:\n",
    "        arr = np.load(f)\n",
    "        if 'use' in f.stem:\n",
    "            b = arr.shape[0]\n",
    "            assert b > end, f\"Incorrect bounds, book only contains {b} sentences\"\n",
    "        elif 'xlm' in f.stem:\n",
    "            b = arr.shape[0]\n",
    "            assert b > end, f\"Incorrect bounds, book only contains {b} sentences\"\n",
    "                \n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "        book = book.replace('_', ' ')\n",
    "               \n",
    "        title = f'{book.title()} {method}'\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if end == -1:\n",
    "            end = len(em)\n",
    "            \n",
    "            \n",
    "        ticks = np.linspace(1, end - start, y, dtype=int)\n",
    "        \n",
    "        if start == 0:\n",
    "            labels = np.linspace(start + 1, end, y, dtype=int)\n",
    "        else:\n",
    "            labels = np.linspace(start, end, y, dtype=int)\n",
    "\n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "            sim = em\n",
    "            print(em.shape)\n",
    "            n = normalize(sim)\n",
    "            np.fill_diagonal(sim, 1)\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "            n = normalize(sim)\n",
    "        \n",
    "        \n",
    "        if std:\n",
    "            numerator = n - np.mean(n)\n",
    "            denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "\n",
    "            ab1 = numerator / denominator\n",
    "            n = ab1\n",
    "            \n",
    "            if np.min(n) < 0:\n",
    "                vmin = int(np.min(n)) - 1\n",
    "            vmax = int(np.max(n)) + 1\n",
    "            \n",
    "            if end == -1:\n",
    "                sns.heatmap(n[start:, start:], cmap='hot', \n",
    "                        vmin=vmin, vmax=vmax, square=True, \n",
    "                        xticklabels=False)\n",
    "            else:\n",
    "                sns.heatmap(n[start:end, start:end], cmap='hot', \n",
    "                        vmin=vmin, vmax=vmax, square=True, \n",
    "                        xticklabels=False)\n",
    "        else:\n",
    "            if end == -1:\n",
    "                sns.heatmap(n[start:, start:], cmap='hot', \n",
    "                        vmin=0, vmax=1, square=True, \n",
    "                        xticklabels=False)\n",
    "            else:\n",
    "                sns.heatmap(n[start:end, start:end], cmap='hot', \n",
    "                        vmin=0, vmax=1, square=True, \n",
    "                        xticklabels=False)\n",
    "#         d[method] = n\n",
    "        plt.yticks(ticks, labels, rotation = 0)\n",
    "#         plt.title(title)\n",
    "        plt.ylabel('sentence number')\n",
    "        plt.savefig(new_path/f'{title}.png', dpi = 300, bbox_inches='tight')\n",
    "        print(f'Done plotting {title}.png')\n",
    "        plt.clf()\n",
    "        del em, sim, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 npy files\n",
      "---------------------------------------------\n",
      "Done plotting A Modest Proposal DeCLUTR Small.png\n",
      "Done plotting A Modest Proposal RoBERTa.png\n",
      "Done plotting A Modest Proposal InferSent GloVe.png\n",
      "Done plotting A Modest Proposal InferSent FastText.png\n",
      "Done plotting A Modest Proposal DistilBERT.png\n",
      "Done plotting A Modest Proposal XLM.png\n",
      "Done plotting A Modest Proposal MPNet.png\n",
      "Done plotting A Modest Proposal USE.png\n",
      "Done plotting A Modest Proposal DeCLUTR Base.png\n",
      "Done plotting A Modest Proposal MiniLM.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| local\n",
    "plot_novels('embeddings/A_Modest_Proposal/', start=10, end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4662490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def plot_histograms(\n",
    "    path: str, # path for embeddings\n",
    "    std: bool=False, # flag to standardize\n",
    "    ):\n",
    "    \"Generates histograms for embeddings in the folder\"\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    if std:\n",
    "        new_path = curr/f'histogram_std'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/f'histogram'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "            \n",
    "        \n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "               \n",
    "        title = f\"{book.replace('_', ' ').title()}\"\n",
    "\n",
    "        em = np.load(f)\n",
    "\n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "            sim = em\n",
    "            print(em.shape)\n",
    "            n = normalize(sim)\n",
    "            np.fill_diagonal(sim, 1)\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "            n = normalize(sim)\n",
    "        \n",
    "        \n",
    "        if std:\n",
    "            numerator = n - np.mean(n)\n",
    "            denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "\n",
    "            ab1 = numerator / denominator\n",
    "            n = ab1\n",
    "        \n",
    "        n = n.astype('float32')\n",
    "        print(f'Processed {method}')\n",
    "        d[method] = n.flatten()\n",
    "        del em, sim, n    \n",
    "    \n",
    "    organized_labels = ['DeCLUTR Base', 'InferSent FastText','DistilBERT', 'RoBERTa',\n",
    "                    'USE', 'MPNet', 'XLM', 'MiniLM']\n",
    "\n",
    "    label2 = ['DC', 'I-F', 'DB', 'RB', 'USE', 'MPNet', 'XLM', 'MiniLM']\n",
    "    fig, ax = plt.subplots(4, 2, figsize=(4,6), sharex=True, sharey=True)\n",
    "    ssm_df = pd.DataFrame(d)\n",
    "    k = 0\n",
    "    for row in range(4):\n",
    "        for col in range(2):\n",
    "            x = ssm_df[organized_labels[k]]\n",
    "            sns.histplot(zscore(x), ax=ax[row][col], binwidth=1) # , bins=7\n",
    "            ax[row][col].set_title(label2[k])\n",
    "#             ax[row][col].set_xlim(-5, 5)\n",
    "            if row == 3:\n",
    "                ax[row][col].set_xlabel('')\n",
    "            k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(new_path/f'{title}_hist.png', dpi = 300, bbox_inches='tight')\n",
    "    print(f\"Done plotting {title}.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b04ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def ssms_from_pkl(path: str, # path for pkl file\n",
    "                  start: int=0, # start for section\n",
    "                  end: int=-1, # end for section\n",
    "                  x: bool=False, # x-ticks\n",
    "                  y: int=5, # y-ticks\n",
    "                 ):\n",
    "    \"Generates SSMs from pkl files\"\n",
    "    if start == 0 and end == -1:\n",
    "        pass\n",
    "    else:\n",
    "        assert start < end, 'Incorrect bounds'\n",
    "    \n",
    "    curr = Path.cwd()\n",
    "    if start > 0:\n",
    "        new_path = curr/f'sections_{start} {end}'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/'full_plots'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    files = loader(path, '.pkl')\n",
    "    for f in files:\n",
    "        d = load_dictionary(f)\n",
    "        fname = f.stem.split('_ssms')\n",
    "        for k, v in d.items():\n",
    "            book = fname[0]\n",
    "            title = f'{book.title()} {k}'\n",
    "            sns.heatmap(v, cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "            ticks = np.linspace(1, end - start, y, dtype=int)\n",
    "        \n",
    "            if start == 0:\n",
    "                labels = np.linspace(start + 1, end, y, dtype=int)\n",
    "            else:\n",
    "                labels = np.linspace(start, end, y, dtype=int)\n",
    "                \n",
    "            plt.yticks(ticks, labels, rotation = 0)\n",
    "            plt.ylabel('sentence number')\n",
    "            plt.savefig(new_path/f'{title}.pdf', format='pdf', dpi = 300, bbox_inches='tight')\n",
    "            print(f'Done plotting {title}')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8809d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def corr_heatmaps(path: str, # path for embeddings\n",
    "                 std: bool=False, # standardize or not\n",
    "                 ):\n",
    "    \"Generates correlation plots from normalized SSMs\"\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    new_path = curr/f'corr_ssm'\n",
    "    new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    d = {}\n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "#             print(em.shape)\n",
    "            sim = em\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "        \n",
    "        n = normalize(sim)\n",
    "        \n",
    "        # condition to standardize the \n",
    "        if std:\n",
    "            numerator = n - np.mean(n)\n",
    "            denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "\n",
    "            ab1 = numerator / denominator\n",
    "            d[method] = ab1.flatten()\n",
    "        else:\n",
    "            d[method] = n.flatten()\n",
    "        \n",
    "        print(f'{method}: {n.shape}')\n",
    "        del em, sim, n\n",
    "        \n",
    "    organized_labels = ['DeCLUTR Base','DeCLUTR Small', 'InferSent FastText', \n",
    "                        'InferSent GloVe','DistilBERT', 'RoBERTa', 'USE',\n",
    "                        'Lexical Weights']\n",
    "    df = pd.DataFrame(d)\n",
    "    \n",
    "    df = df[organized_labels]\n",
    "    \n",
    "    corr = df.corr()\n",
    "\n",
    "    sns.heatmap(corr, cmap='hot', vmin=0, vmax=1, \n",
    "                square=True, annot = True,\n",
    "                xticklabels=False,\n",
    "                yticklabels=df.columns,\n",
    "                fmt = '.2f'\n",
    "               )\n",
    "    \n",
    "\n",
    "    title = f'{book.title()}'\n",
    "    \n",
    "    if std:\n",
    "        np.save(new_path/f'{title}_corr_std_ssm.npy', corr)\n",
    "        plt.savefig(new_path/f'{title}_corr_std_ssm.png', dpi = 300, bbox_inches='tight')\n",
    "    else:\n",
    "        np.save(new_path/f'{title}_corr_ssm.npy', corr)\n",
    "#     plt.title(title)\n",
    "#     plt.savefig(new_path/f'{title}_corr_ssm.png', dpi = 300, bbox_inches='tight')\n",
    "    print(f'Done plotting {title}_corr_ssm.png')\n",
    "#     plt.clf()\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f81ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def corr_ts(path: str, # path for embeddings\n",
    "           ):\n",
    "    \"Generates correlation plots from time series\"\n",
    "    files = loader(path, '.pkl')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    new_path = curr/f'corr_ts'\n",
    "    new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    d = {}\n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        fname = open(f, 'rb')\n",
    "        data = pickle.load(fname)\n",
    "        _plot(embedding_path, data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "@call_parse\n",
    "def lex_ts(path: str, # path for embeddings\n",
    "          ):\n",
    "    \"Generate lexical TS from Lexical SSM\"\n",
    "    \n",
    "    files = loader(path, 'wt_ssm.npy')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    for f in files:\n",
    "        em = np.load(f)\n",
    "        x = normalize(em)\n",
    "        np.fill_diagonal(x, 1)\n",
    "        \n",
    "        z = []\n",
    "        for i in range(len(x) - 1):\n",
    "            z.append(x[i][i+1])\n",
    "        \n",
    "        print(len(x))    \n",
    "        np.save(f'{f.stem[:-3]}ts', z)\n",
    "        print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def plot_standardized(path: str, # path for embeddings\n",
    "                start: int=0, # start for section\n",
    "                end: int= -1, # end for section\n",
    "                x: bool=False, # x-ticks\n",
    "                y: int=5, # y-ticks\n",
    "               ):\n",
    "    \"Generates plots for embeddings in the folder\"\n",
    "    \n",
    "    if start > end:\n",
    "        assert 'Incorrect bounds'\n",
    "    \n",
    "    # Marker for xticks and yticks\n",
    "    if x == -1:\n",
    "        x = False\n",
    "    if y == -1:\n",
    "        y = False\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    if start > 0:\n",
    "        new_path = curr/f'sections_{start} {end}'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/'full_plots'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "        \n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "               \n",
    "        title = f'{book.title()} {method}'\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if start == 0:\n",
    "            start = 1\n",
    "        \n",
    "        if end == -1:\n",
    "            end = len(em)\n",
    "            \n",
    "            \n",
    "        ticks = np.linspace(1, end - start, 5, dtype=int)\n",
    "        labels = np.linspace(start, end, 5, dtype=int)\n",
    "\n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "            sim = em\n",
    "            print(em.shape)\n",
    "            n = normalize(sim)\n",
    "            np.fill_diagonal(sim, 1)\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "            n = normalize(sim)\n",
    "        \n",
    "        \n",
    "        numerator = n - np.mean(n)\n",
    "        denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "    \n",
    "        ab1 = numerator / denominator\n",
    "        \n",
    "        sns.heatmap(ab1[start:end, start:end], cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "        \n",
    "        \n",
    "        plt.yticks(ticks, labels, rotation = 0)\n",
    "#         plt.title(title)\n",
    "        plt.ylabel('sentence number')\n",
    "        plt.savefig(new_path/f'{title}.png', dpi = 300, bbox_inches='tight')\n",
    "        plt.savefig(new_path/f'{title}.pdf', dpi = 300, bbox_inches='tight')\n",
    "        print(f'Done plotting {title}')\n",
    "        plt.clf()\n",
    "        del em, sim, n, numerator, denominator, ab1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
