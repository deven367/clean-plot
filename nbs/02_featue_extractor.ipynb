{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Feature Extractor and Logistic Regression Classifier\n",
    "\n",
    "> This notebook goes over how to get features using VGG16 and use a logistic regression classifier to predict whether the image contains flood or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# example of using the vgg16 model as a feature extraction model\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Flatten\n",
    "# from pickle import dump\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_features(path):\n",
    "    '''\n",
    "    This function outputs the features from the VGG16 architecture (7x7x512) and flattens it a\n",
    "    and returns it as an .npy array\n",
    "    '''\n",
    "\n",
    "    all_features = []\n",
    "    for fx in sorted(os.listdir(path)):\n",
    "        if fx.endswith('.jpg'):\n",
    "            image = load_img(path+fx, target_size=(224, 224))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            # get extracted features\n",
    "            # features = model.predict(image)\n",
    "            features = vgg16.predict(image)\n",
    "\n",
    "            # print(features.shape)\n",
    "            # print(features.reshape(-1,).shape)\n",
    "            # all_features.append(features.reshape(-1,))\n",
    "            all_features.append(features.flatten())\n",
    "            print('Done with {}'.format(fx[:-4]))\n",
    "    return np.asarray(all_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_features(path):\n",
    "    '''\n",
    "    This function outputs the features from the VGG16 architecture (7x7x512) and flattens it a\n",
    "    and returns it as an .npy array\n",
    "    '''\n",
    "\n",
    "    all_features = []\n",
    "    for fx in sorted(os.listdir(path)):\n",
    "        if fx.endswith('.jpg'):\n",
    "            image = load_img(path+fx, target_size=(224, 224))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            # get extracted features\n",
    "            # features = model.predict(image)\n",
    "            features = vgg16.predict(image)\n",
    "\n",
    "            # print(features.shape)\n",
    "            # print(features.reshape(-1,).shape)\n",
    "            # all_features.append(features.reshape(-1,))\n",
    "            all_features.append(features.flatten())\n",
    "            print('Done with {}'.format(fx[:-4]))\n",
    "    return np.asarray(all_features)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
