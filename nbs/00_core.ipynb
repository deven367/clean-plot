{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> The module contains all the basics functions to load documents, `.txt` files and `.npy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Callable, Iterator, Union, Optional, List\n",
    "import pathlib\n",
    "import glob\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data(fname: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads from a txt file\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        all_text = f.read()\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_pmi(fname: Union[str, pathlib.Path]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the PMI matrix\n",
    "    \"\"\"\n",
    "    file_ = loader(fname, '.npy')\n",
    "    pmi = np.load(file_)\n",
    "    print(f'Loaded {name}')\n",
    "    return pmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dictionary(fname):\n",
    "    \"\"\"\n",
    "    Given a fname, function loads a `pkl` dictionary\n",
    "    from the current directory\n",
    "\n",
    "    Args:\n",
    "        fname ([str]): Enter the filename\n",
    "\n",
    "    Returns:\n",
    "        [dict]: Returns the loaded pkl file as a\n",
    "                dict\n",
    "    \"\"\"\n",
    "    fname = open(fname, 'rb')\n",
    "    data = pickle.load(fname)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def loader(path: Union[str, pathlib.Path], extension: str) -> Union[None, List[pathlib.PosixPath]]:\n",
    "    \"\"\"\n",
    "    Given a Path and an extension, returns all files with the extension in the path\n",
    "    \"\"\"\n",
    "    #`Note` Recursive not supported yet\n",
    "    p = Path(path)\n",
    "    files = []\n",
    "    for file_ in p.glob(f'*{extension}'):\n",
    "        files.append(file_)\n",
    "    \n",
    "    if files == []:\n",
    "        print(f'Directory does not contain files ending in {extension}')\n",
    "        return\n",
    "    elif len(files) == 1:\n",
    "        return files[0]\n",
    "    return files\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not contain files ending in .pg\n"
     ]
    }
   ],
   "source": [
    "loader('D:/college/UC/AAthesis/stats', '.pg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def iterator(path):\n",
    "    for fx in os.listdir(path):\n",
    "        if fx.endswith('.pkl'):\n",
    "            d = load_dictionary(path+fx)\n",
    "            \n",
    "        if fx.endswith('_norm.npy'):\n",
    "            pmi = load_pmi(path+fx)\n",
    "            \n",
    "        if fx.endswith('lexical.txt'):\n",
    "            data = get_data(path+fx)\n",
    "            sentences = split_by_newline(data)\n",
    "            \n",
    "    return pmi, d, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function lets you say hello to anyone!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
