{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp heatmaps_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac9241",
   "metadata": {},
   "source": [
    "# Heatmaps for novels\n",
    "> This module is to create heatmaps for novels. It even includes some functions to generate smaller heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from clean_plot.core import loader, load_dictionary\n",
    "from clean_plot.pickle import label\n",
    "from clean_plot.functions import normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastcore.all import *\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea177d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def plot_novels(path: str, # path for embeddings\n",
    "                start: int=0, # start for section\n",
    "                end: int= -1, # end for section\n",
    "                x: bool=False, # x-ticks\n",
    "                y: int=5, # y-ticks\n",
    "               ):\n",
    "    \"Generates plots for embeddings in the folder\"\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    if start == 0 and end == -1:\n",
    "        pass\n",
    "    else:\n",
    "        assert start < end, 'Incorrect bounds'\n",
    "    \n",
    "    # Marker for xticks and yticks\n",
    "    if x == -1:\n",
    "        x = False\n",
    "    if y == -1:\n",
    "        y = False\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    if start > 0:\n",
    "        new_path = curr/f'sections_{start} {end}'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/'full_plots'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "        \n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "               \n",
    "        title = f'{book.title()} {method}'\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if end == -1:\n",
    "            end = len(em)\n",
    "            \n",
    "            \n",
    "        ticks = np.linspace(1, end - start, y, dtype=int)\n",
    "        \n",
    "        if start == 0:\n",
    "            labels = np.linspace(start + 1, end, y, dtype=int)\n",
    "        else:\n",
    "            labels = np.linspace(start, end, y, dtype=int)\n",
    "\n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "            sim = em\n",
    "            print(em.shape)\n",
    "            n = normalize(sim)\n",
    "            np.fill_diagonal(sim, 1)\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "            n = normalize(sim)\n",
    "        \n",
    "        \n",
    "        if end == -1:\n",
    "            sns.heatmap(n[start:, start:], cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "        else:\n",
    "            sns.heatmap(n[start:end, start:end], cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "        d[method] = n\n",
    "        plt.yticks(ticks, labels, rotation = 0)\n",
    "#         plt.title(title)\n",
    "        plt.ylabel('sentence number')\n",
    "        plt.savefig(new_path/f'{title}.png', dpi = 300, bbox_inches='tight')\n",
    "        print(f'Done plotting {title}.png')\n",
    "        plt.clf()\n",
    "        del em, sim, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b04ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def ssms_from_pkl(path: str, # path for pkl file\n",
    "                  start: int=0, # start for section\n",
    "                  end: int=-1, # end for section\n",
    "                  x: bool=False, # x-ticks\n",
    "                  y: int=5, # y-ticks\n",
    "                 ):\n",
    "    \"Generates SSMs from pkl files\"\n",
    "    if start == 0 and end == -1:\n",
    "        pass\n",
    "    else:\n",
    "        assert start < end, 'Incorrect bounds'\n",
    "    \n",
    "    curr = Path.cwd()\n",
    "    if start > 0:\n",
    "        new_path = curr/f'sections_{start} {end}'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/'full_plots'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    files = loader(path, '.pkl')\n",
    "    for f in files:\n",
    "        d = load_dictionary(f)\n",
    "        fname = f.stem.split('_ssms')\n",
    "        for k, v in d.items():\n",
    "            book = fname[0]\n",
    "            title = f'{book.title()} {k}'\n",
    "            sns.heatmap(v, cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "            ticks = np.linspace(1, end - start, y, dtype=int)\n",
    "        \n",
    "            if start == 0:\n",
    "                labels = np.linspace(start + 1, end, y, dtype=int)\n",
    "            else:\n",
    "                labels = np.linspace(start, end, y, dtype=int)\n",
    "                \n",
    "            plt.yticks(ticks, labels, rotation = 0)\n",
    "            plt.ylabel('sentence number')\n",
    "            plt.savefig(new_path/f'{title}.pdf', format='pdf', dpi = 300, bbox_inches='tight')\n",
    "            print(f'Done plotting {title}')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8809d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def corr_heatmaps(path: str, # path for embeddings\n",
    "                 std: bool=False, # standardize or not\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Generates correlation plots from normalized SSMs\n",
    "    \"\"\"\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    new_path = curr/f'corr_ssm'\n",
    "    new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    d = {}\n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "#             print(em.shape)\n",
    "            sim = em\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "        \n",
    "        n = normalize(sim)\n",
    "        \n",
    "        # condition to standardize the \n",
    "        if std:\n",
    "            numerator = n - np.mean(n)\n",
    "            denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "\n",
    "            ab1 = numerator / denominator\n",
    "            d[method] = ab1.flatten()\n",
    "        else:\n",
    "            d[method] = n.flatten()\n",
    "        \n",
    "        print(f'{method}: {n.shape}')\n",
    "        del em, sim, n\n",
    "        \n",
    "    organized_labels = ['DeCLUTR Base','DeCLUTR Small', 'InferSent FastText', \n",
    "                        'InferSent GloVe','DistilBERT', 'RoBERTa', 'USE',\n",
    "                        'Lexical Weights']\n",
    "    df = pd.DataFrame(d)\n",
    "    \n",
    "    df = df[organized_labels]\n",
    "    \n",
    "    corr = df.corr()\n",
    "\n",
    "    sns.heatmap(corr, cmap='hot', vmin=0, vmax=1, \n",
    "                square=True, annot = True,\n",
    "                xticklabels=False,\n",
    "                yticklabels=df.columns,\n",
    "                fmt = '.2f'\n",
    "               )\n",
    "    \n",
    "\n",
    "    title = f'{book.title()}'\n",
    "    \n",
    "    if std:\n",
    "        np.save(new_path/f'{title}_corr_std_ssm.npy', corr)\n",
    "        plt.savefig(new_path/f'{title}_corr_std_ssm.png', dpi = 300, bbox_inches='tight')\n",
    "    else:\n",
    "        np.save(new_path/f'{title}_corr_ssm.npy', corr)\n",
    "#     plt.title(title)\n",
    "#     plt.savefig(new_path/f'{title}_corr_ssm.png', dpi = 300, bbox_inches='tight')\n",
    "    print(f'Done plotting {title}_corr_ssm.png')\n",
    "#     plt.clf()\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f81ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def corr_ts(path: str, # path for embeddings\n",
    "           ):\n",
    "    \"\"\"\n",
    "    Generates correlation plots from time series\n",
    "    \"\"\"\n",
    "    files = loader(path, '.pkl')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    new_path = curr/f'corr_ts'\n",
    "    new_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    d = {}\n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        fname = open(f, 'rb')\n",
    "        data = pickle.load(fname)\n",
    "        _plot(embedding_path, data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "@call_parse\n",
    "def lex_ts(path: str, # path for embeddings\n",
    "          ):\n",
    "    \"\"\"\n",
    "    Generate lexical TS from Lexical SSM\n",
    "    \"\"\"\n",
    "    \n",
    "    files = loader(path, 'wt_ssm.npy')\n",
    "    curr = Path.cwd()\n",
    "    \n",
    "    for f in files:\n",
    "        em = np.load(f)\n",
    "        x = normalize(em)\n",
    "        np.fill_diagonal(x, 1)\n",
    "        \n",
    "        z = []\n",
    "        for i in range(len(x) - 1):\n",
    "            z.append(x[i][i+1])\n",
    "        \n",
    "        print(len(x))    \n",
    "        np.save(f'{f.stem[:-3]}ts', z)\n",
    "        print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def plot_standardized(path: str, # path for embeddings\n",
    "                start: int=0, # start for section\n",
    "                end: int= -1, # end for section\n",
    "                x: bool=False, # x-ticks\n",
    "                y: int=5, # y-ticks\n",
    "               ):\n",
    "    \"Generates plots for embeddings in the folder\"\n",
    "    \n",
    "    if start > end:\n",
    "        assert 'Incorrect bounds'\n",
    "    \n",
    "    # Marker for xticks and yticks\n",
    "    if x == -1:\n",
    "        x = False\n",
    "    if y == -1:\n",
    "        y = False\n",
    "    \n",
    "    files = loader(path, '.npy')\n",
    "    curr = Path.cwd()\n",
    "    if start > 0:\n",
    "        new_path = curr/f'sections_{start} {end}'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        new_path = curr/'full_plots'\n",
    "        new_path.mkdir(exist_ok=True)\n",
    "        \n",
    "    for f in files:\n",
    "        fname = f.stem.split('_cleaned_')\n",
    "        book, method = fname[0], label(fname[1])\n",
    "               \n",
    "        title = f'{book.title()} {method}'\n",
    "\n",
    "        em = np.load(f)\n",
    "        \n",
    "        if start == 0:\n",
    "            start = 1\n",
    "        \n",
    "        if end == -1:\n",
    "            end = len(em)\n",
    "            \n",
    "            \n",
    "        ticks = np.linspace(1, end - start, 5, dtype=int)\n",
    "        labels = np.linspace(start, end, 5, dtype=int)\n",
    "\n",
    "        if fname[1] == 'lexical_wt_ssm':\n",
    "            sim = em\n",
    "            print(em.shape)\n",
    "            n = normalize(sim)\n",
    "            np.fill_diagonal(sim, 1)\n",
    "        else:\n",
    "            sim = cosine_similarity(em, em)\n",
    "            n = normalize(sim)\n",
    "        \n",
    "        \n",
    "        numerator = n - np.mean(n)\n",
    "        denominator = np.sqrt(np.sum(numerator**2) / (numerator.size - 1) )\n",
    "    \n",
    "        ab1 = numerator / denominator\n",
    "        \n",
    "        sns.heatmap(ab1[start:end, start:end], cmap='hot', \n",
    "                    vmin=0, vmax=1, square=True, \n",
    "                    xticklabels=False)\n",
    "        \n",
    "        \n",
    "        plt.yticks(ticks, labels, rotation = 0)\n",
    "#         plt.title(title)\n",
    "        plt.ylabel('sentence number')\n",
    "        plt.savefig(new_path/f'{title}.png', dpi = 300, bbox_inches='tight')\n",
    "        plt.savefig(new_path/f'{title}.pdf', dpi = 300, bbox_inches='tight')\n",
    "        print(f'Done plotting {title}')\n",
    "        plt.clf()\n",
    "        del em, sim, n, numerator, denominator, ab1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
