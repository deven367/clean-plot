{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Feature Extractor and Logistic Regression Classifier\n",
    "\n",
    "> This notebook goes over how to get features using VGG16 and use a logistic regression classifier to predict whether the image contains flood or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# example of using the vgg16 model as a feature extraction model\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Flatten\n",
    "# from pickle import dump\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\r\n",
    "def get_features(path):\r\n",
    "    '''\r\n",
    "    This function outputs the features from the VGG16 architecture (7x7x512) and flattens it a\r\n",
    "    and returns it as an .npy array\r\n",
    "    '''\r\n",
    "\r\n",
    "    all_features = []\r\n",
    "    for fx in sorted(os.listdir(path)):\r\n",
    "        if fx.endswith('.jpg'):\r\n",
    "            image = load_img(path+fx, target_size=(224, 224))\r\n",
    "            # convert the image pixels to a numpy array\r\n",
    "            image = img_to_array(image)\r\n",
    "\r\n",
    "            # reshape data for the model\r\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\n",
    "\r\n",
    "            # prepare the image for the VGG model\r\n",
    "            image = preprocess_input(image)\r\n",
    "\r\n",
    "            # get extracted features\r\n",
    "            # features = model.predict(image)\r\n",
    "            features = vgg16.predict(image)\r\n",
    "\r\n",
    "            # print(features.shape)\r\n",
    "            # print(features.reshape(-1,).shape)\r\n",
    "            # all_features.append(features.reshape(-1,))\r\n",
    "            all_features.append(features.flatten())\r\n",
    "            print('Done with {}'.format(fx[:-4]))\r\n",
    "    return np.asarray(all_features)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 32-bit",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
